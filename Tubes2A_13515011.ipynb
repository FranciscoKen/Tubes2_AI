{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas Besar IF3170 Inteligensi Buatan\n",
    "\n",
    "## Dibuat oleh Kelompok 2: Pejuang AI\n",
    "\n",
    "### - Reinhard Benjamin L / 13515011\n",
    "### - Putu Arya P. / 13515017\n",
    "### - Raihan Muhammad Suria N. / 13515128\n",
    "### - Dicky Novanto / 13515134\n",
    "### - Francisco Kenandi / 13515140\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membaca data training dari file eksternal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "X = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "print(\"Overview data:\")\n",
    "print(X.head())\n",
    "target = X[\"50K\"]\n",
    "print(\"\\n\\nTARGET: \")\n",
    "print(target.head())\n",
    "\n",
    "census = X[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "\n",
    "\n",
    "print(\"\\n\\nDATA: \")\n",
    "print(census.head())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan training dengan algoritma pembelajaran KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan KNN , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#iris = datasets.load_iris()\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None,na_values=[\"?\"], names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "    \n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "    \n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "test = kf.split(new_data)\n",
    "jumlah = 0;\n",
    "nomorFold = 1\n",
    "for train_index,test_index in test:\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset\n",
    "    knn = KNeighborsClassifier(n_neighbors = 21,p=1)\n",
    "    knn.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = knn.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100, \"%\")\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "    \n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan training dengan algoritma pembelajaran Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Naive Bayes , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, na_values=[\"?\"], names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "\n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah = 0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = gnb.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "    \n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan training dengan algoritma pembelajaran Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Decision Tree , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None,na_values=[\"?\"], names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "\n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah=0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    clf = tree.DecisionTreeClassifier(criterion = \"entropy\",max_depth=10)\n",
    "    clf.fit(data_train,target_train)\n",
    "    print(\"fold ke \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = clf.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "\n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan training dengan algoritma pembelajaran Multilayer Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan MLP , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None,na_values=[\"?\"], names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "\n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah = 0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    clf = MLPClassifier(activation='logistic',max_iter = 1000,solver='lbfgs',hidden_layer_sizes=(50,2),verbose=True)\n",
    "    clf.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = clf.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "\n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan full training dengan algoritma pembelajaran Decision Tree\n",
    "### (Menghasilkan model ke file eksternal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Decision Tree, metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from statistics import mode\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS UNTUK TRAINING\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\\s\",header=None,na_values=[\"?\"], names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"], engine='python')\n",
    "\n",
    "#add & uncomment these two if you want to ignore the ? value\n",
    "#, na_values=[\"?\"]\n",
    "#cen.dropna(inplace=True)\n",
    "\n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \"<=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \">50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "list_census = (list(new_data.columns.values))\n",
    "print(\"new data:\\n\")\n",
    "print(new_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "\n",
    "#learning dataset    \n",
    "clf = tree.DecisionTreeClassifier(criterion = \"entropy\",max_depth=10)\n",
    "clf.fit(new_data,new)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf,'clf.pkl') # menyimpan model ke file eksternal\n",
    "print('\\nModel Saved!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melakukan testing terhadap dataset test dengan algoritma pembelajaran Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing dengan algoritma Decision Tree, metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "from statistics import mode\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS UNTUK TESTING\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.test.txt', sep=\",\\s\",na_values=[\"?\"],header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"], engine='python')\n",
    "\n",
    "#add & uncomment these two if you want to ignore the ? value\n",
    "#, na_values=[\"?\"]\n",
    "\n",
    "#changing missing value into mode\n",
    "cen[\"workclass\"]=cen[\"workclass\"].fillna(mode(cen[\"workclass\"]))\n",
    "cen[\"education\"]=cen[\"education\"].fillna(mode(cen[\"education\"]))\n",
    "cen[\"marital-status\"]=cen[\"marital-status\"].fillna(mode(cen[\"marital-status\"]))\n",
    "cen[\"occupation\"]=cen[\"occupation\"].fillna(mode(cen[\"occupation\"]))\n",
    "cen[\"relationship\"]=cen[\"relationship\"].fillna(mode(cen[\"relationship\"]))\n",
    "cen[\"race\"]=cen[\"race\"].fillna(mode(cen[\"race\"]))\n",
    "cen[\"sex\"]=cen[\"sex\"].fillna(mode(cen[\"sex\"]))\n",
    "cen[\"native-country\"]=cen[\"native-country\"].fillna(mode(cen[\"native-country\"]))\n",
    "\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \"<=50K.\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \">50K.\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "\n",
    "new_data = pd.get_dummies(census_data)\n",
    "\n",
    "\n",
    "#Fixing unbalanced column problem\n",
    "list_target = (list(new_data.columns.values))\n",
    "\n",
    "empty_list = (list(set(list_census) - set(list_target)))\n",
    "\n",
    "while (len(empty_list) > 0):\n",
    "    new_data[empty_list.pop()] = 0\n",
    "\n",
    "new_data = new_data.values\n",
    "print(\"new_data:\\n\")\n",
    "print(new_data)\n",
    "clf = joblib.load('clf.pkl') # membaca model dari file eksternal\n",
    "print('\\nModel Loaded!')\n",
    "\n",
    "\n",
    "\n",
    "#predicting learning data \n",
    "prediction = clf.predict(new_data)\n",
    "print('PREDICTION: ',prediction)\n",
    "print('\\n\\nTARGET TEST : ',new)\n",
    "\n",
    "#lihat akurasi\n",
    "print('\\nAccuracy:')\n",
    "acc = accuracy_score(new,prediction)\n",
    "print(acc*100,'%')\n",
    "\n",
    "graph = Source( tree.export_graphviz(clf, out_file=None))\n",
    "png_bytes = graph.pipe(format='png')\n",
    "with open('dtree_pipe.png','wb') as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(png_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
