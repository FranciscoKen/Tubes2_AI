{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview data:\n",
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country     50K  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "\n",
      "\n",
      "TARGET: \n",
      "0     <=50K\n",
      "1     <=50K\n",
      "2     <=50K\n",
      "3     <=50K\n",
      "4     <=50K\n",
      "Name: 50K, dtype: object\n",
      "\n",
      "\n",
      "DATA: \n",
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  \n",
      "0          2174             0              40   United-States  \n",
      "1             0             0              13   United-States  \n",
      "2             0             0              40   United-States  \n",
      "3             0             0              40   United-States  \n",
      "4             0             0              40            Cuba  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "X = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "print(\"Overview data:\")\n",
    "print(X.head())\n",
    "target = X[\"50K\"]\n",
    "print(\"\\n\\nTARGET: \")\n",
    "print(target.head())\n",
    "\n",
    "census = X[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "\n",
    "\n",
    "print(\"\\n\\nDATA: \")\n",
    "print(census.head())\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold ke:  1\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 1.  0.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2404   31]\n",
      " [ 623  199]]\n",
      "\n",
      "Accuracy:\n",
      "79.9201719374 %\n",
      "\n",
      "Precission:\n",
      "0.865217391304\n",
      "\n",
      "Recall:\n",
      "0.242092457421\n",
      "\n",
      "\n",
      "fold ke:  2\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2437   41]\n",
      " [ 614  164]]\n",
      "\n",
      "Accuracy:\n",
      "79.8832923833 %\n",
      "\n",
      "Precission:\n",
      "0.8\n",
      "\n",
      "Recall:\n",
      "0.210796915167\n",
      "\n",
      "\n",
      "fold ke:  3\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "TARGET TEST :  [ 0.  0.  1. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2466   39]\n",
      " [ 596  155]]\n",
      "\n",
      "Accuracy:\n",
      "80.4975429975 %\n",
      "\n",
      "Precission:\n",
      "0.798969072165\n",
      "\n",
      "Recall:\n",
      "0.206391478029\n",
      "\n",
      "\n",
      "fold ke:  4\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2431   44]\n",
      " [ 605  176]]\n",
      "\n",
      "Accuracy:\n",
      "80.0675675676 %\n",
      "\n",
      "Precission:\n",
      "0.8\n",
      "\n",
      "Recall:\n",
      "0.225352112676\n",
      "\n",
      "\n",
      "fold ke:  5\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  1. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2434   44]\n",
      " [ 612  166]]\n",
      "\n",
      "Accuracy:\n",
      "79.8525798526 %\n",
      "\n",
      "Precission:\n",
      "0.790476190476\n",
      "\n",
      "Recall:\n",
      "0.213367609254\n",
      "\n",
      "\n",
      "fold ke:  6\n",
      "PREDICTION:  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  1.  1. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2441   43]\n",
      " [ 590  182]]\n",
      "\n",
      "Accuracy:\n",
      "80.558968059 %\n",
      "\n",
      "Precission:\n",
      "0.808888888889\n",
      "\n",
      "Recall:\n",
      "0.235751295337\n",
      "\n",
      "\n",
      "fold ke:  7\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2422   33]\n",
      " [ 634  167]]\n",
      "\n",
      "Accuracy:\n",
      "79.5147420147 %\n",
      "\n",
      "Precission:\n",
      "0.835\n",
      "\n",
      "Recall:\n",
      "0.208489388265\n",
      "\n",
      "\n",
      "fold ke:  8\n",
      "PREDICTION:  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  1.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2435   25]\n",
      " [ 627  169]]\n",
      "\n",
      "Accuracy:\n",
      "79.9754299754 %\n",
      "\n",
      "Precission:\n",
      "0.871134020619\n",
      "\n",
      "Recall:\n",
      "0.212311557789\n",
      "\n",
      "\n",
      "fold ke:  9\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  1.  0. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2418   43]\n",
      " [ 599  196]]\n",
      "\n",
      "Accuracy:\n",
      "80.2825552826 %\n",
      "\n",
      "Precission:\n",
      "0.820083682008\n",
      "\n",
      "Recall:\n",
      "0.246540880503\n",
      "\n",
      "\n",
      "fold ke:  10\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  1. ...,  1.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2442   47]\n",
      " [ 601  166]]\n",
      "\n",
      "Accuracy:\n",
      "80.0982800983 %\n",
      "\n",
      "Precission:\n",
      "0.779342723005\n",
      "\n",
      "Recall:\n",
      "0.216427640156\n",
      "\n",
      "\n",
      "Rata-rata accuracy:  80.0651130168 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training dengan KNN , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#iris = datasets.load_iris()\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "    \n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "test = kf.split(new_data)\n",
    "jumlah = 0;\n",
    "nomorFold = 1\n",
    "for train_index,test_index in test:\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset\n",
    "    knn = KNeighborsClassifier(n_neighbors = 21,p=1)\n",
    "    knn.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = knn.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100, \"%\")\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "    \n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold ke:  1\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2351  116]\n",
      " [ 545  245]]\n",
      "\n",
      "Accuracy:\n",
      "79.7052502303 %\n",
      "\n",
      "Precission:\n",
      "0.678670360111\n",
      "\n",
      "Recall:\n",
      "0.310126582278\n",
      "\n",
      "\n",
      "fold ke:  2\n",
      "PREDICTION:  [ 1.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 1.  0.  0. ...,  1.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2347  117]\n",
      " [ 556  236]]\n",
      "\n",
      "Accuracy:\n",
      "79.3304668305 %\n",
      "\n",
      "Precission:\n",
      "0.668555240793\n",
      "\n",
      "Recall:\n",
      "0.29797979798\n",
      "\n",
      "\n",
      "fold ke:  3\n",
      "PREDICTION:  [ 1.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 1.  0.  0. ...,  0.  1.  0.]\n",
      "Confusion Matrix:\n",
      "[[2368  118]\n",
      " [ 510  260]]\n",
      "\n",
      "Accuracy:\n",
      "80.7125307125 %\n",
      "\n",
      "Precission:\n",
      "0.687830687831\n",
      "\n",
      "Recall:\n",
      "0.337662337662\n",
      "\n",
      "\n",
      "fold ke:  4\n",
      "PREDICTION:  [ 0.  0.  1. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2308  147]\n",
      " [ 546  255]]\n",
      "\n",
      "Accuracy:\n",
      "78.7162162162 %\n",
      "\n",
      "Precission:\n",
      "0.634328358209\n",
      "\n",
      "Recall:\n",
      "0.318352059925\n",
      "\n",
      "\n",
      "fold ke:  5\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 1.  0.  1. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2339  115]\n",
      " [ 557  245]]\n",
      "\n",
      "Accuracy:\n",
      "79.3611793612 %\n",
      "\n",
      "Precission:\n",
      "0.680555555556\n",
      "\n",
      "Recall:\n",
      "0.305486284289\n",
      "\n",
      "\n",
      "fold ke:  6\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 1.  0.  1. ...,  0.  1.  0.]\n",
      "Confusion Matrix:\n",
      "[[2352  111]\n",
      " [ 556  237]]\n",
      "\n",
      "Accuracy:\n",
      "79.5147420147 %\n",
      "\n",
      "Precission:\n",
      "0.681034482759\n",
      "\n",
      "Recall:\n",
      "0.298865069357\n",
      "\n",
      "\n",
      "fold ke:  7\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  1.  0.]\n",
      "TARGET TEST :  [ 0.  0.  1. ...,  0.  1.  1.]\n",
      "Confusion Matrix:\n",
      "[[2334  134]\n",
      " [ 541  247]]\n",
      "\n",
      "Accuracy:\n",
      "79.269041769 %\n",
      "\n",
      "Precission:\n",
      "0.648293963255\n",
      "\n",
      "Recall:\n",
      "0.31345177665\n",
      "\n",
      "\n",
      "fold ke:  8\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2340  141]\n",
      " [ 539  236]]\n",
      "\n",
      "Accuracy:\n",
      "79.1154791155 %\n",
      "\n",
      "Precission:\n",
      "0.62599469496\n",
      "\n",
      "Recall:\n",
      "0.304516129032\n",
      "\n",
      "\n",
      "fold ke:  9\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  1.]\n",
      "Confusion Matrix:\n",
      "[[2318  140]\n",
      " [ 550  248]]\n",
      "\n",
      "Accuracy:\n",
      "78.8083538084 %\n",
      "\n",
      "Precission:\n",
      "0.639175257732\n",
      "\n",
      "Recall:\n",
      "0.310776942356\n",
      "\n",
      "\n",
      "fold ke:  10\n",
      "PREDICTION:  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "TARGET TEST :  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Confusion Matrix:\n",
      "[[2395  129]\n",
      " [ 504  228]]\n",
      "\n",
      "Accuracy:\n",
      "80.558968059 %\n",
      "\n",
      "Precission:\n",
      "0.638655462185\n",
      "\n",
      "Recall:\n",
      "0.311475409836\n",
      "\n",
      "\n",
      "Rata-rata accuracy:  79.5092228117 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training dengan Naive Bayes , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "    \n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah = 0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = gnb.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "    \n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Decision Tree , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "    \n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah=0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    clf = tree.DecisionTreeClassifier(criterion = \"entropy\",max_depth=10)\n",
    "    clf.fit(data_train,target_train)\n",
    "    print(\"fold ke \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = clf.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "\n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan MLP , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\", header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"])\n",
    "    \n",
    "census_data = cen[[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \" <=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \" >50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "split_number = 10\n",
    "\n",
    "#folding\n",
    "kf = KFold(n_splits=split_number,shuffle= True)\n",
    "jumlah = 0\n",
    "nomorFold = 1\n",
    "for train_index,test_index in kf.split(new_data):\n",
    "    data_train,data_test = new_data[train_index],new_data[test_index]\n",
    "    target_train,target_test = new[train_index], new[test_index]\n",
    "    \n",
    "    #learning dataset    \n",
    "    clf = MLPClassifier(activation='logistic',max_iter = 1000,solver='lbfgs',hidden_layer_sizes=(20,20))\n",
    "    clf.fit(data_train,target_train)\n",
    "    print(\"fold ke: \",nomorFold)\n",
    "    #predicting learning data \n",
    "    prediction = clf.predict(data_test)\n",
    "    print('PREDICTION: ',prediction)\n",
    "    print('TARGET TEST : ',target_test)\n",
    "    \n",
    "    #generating confusion matrix\n",
    "    #conf_matrix = \n",
    "    conf = confusion_matrix(target_test,prediction)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf)\n",
    "    \n",
    "    #accuracy\n",
    "    print('\\nAccuracy:')\n",
    "    acc = accuracy_score(target_test,prediction)\n",
    "    jumlah+=acc\n",
    "    print(acc*100,'%')\n",
    "    \n",
    "    #precision\n",
    "    print('\\nPrecission:')\n",
    "    prec = precision_score(target_test,prediction)\n",
    "    print(prec)\n",
    "    \n",
    "    #recall\n",
    "    print('\\nRecall:')\n",
    "    rec = recall_score(target_test,prediction)\n",
    "    print(rec)\n",
    "    print('\\n')\n",
    "    nomorFold+=1\n",
    "\n",
    "average = jumlah/10;\n",
    "print('Rata-rata accuracy: ',average*100,'%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Decision Tree , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS UNTUK TRAINING\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.data.txt', sep=\",\\s\",header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"], engine='python')\n",
    "\n",
    "#add & uncomment these two if you want to ignore the ? value\n",
    "#, na_values=[\"?\"]\n",
    "#cen.dropna(inplace=True)\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \"<=50K\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \">50K\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "            \n",
    "new_data = pd.get_dummies(census_data)\n",
    "list_census = (list(new_data.columns.values))\n",
    "print(new_data)\n",
    "new_data = new_data.values\n",
    "\n",
    "\n",
    "\n",
    "#learning dataset    \n",
    "clf = tree.DecisionTreeClassifier(criterion = \"entropy\",max_depth=10)\n",
    "clf.fit(new_data,new)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf,'clf.pkl') # menyimpan model ke file eksternal\n",
    "print('Model Saved!')\n",
    "\n",
    "huehue = joblib.load('clf.pkl') # membaca model dari file eksternal\n",
    "print('Model Loaded!')\n",
    "print(huehue)\n",
    "\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dengan Decision Tree , kFold 10 fold , metrics, confusion matrix \n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "\n",
    "#PEMBACAAN DATASET CENSUS UNTUK TESTING\n",
    "cen = pd.read_csv('DatasetEskperimen/CensusIncome/CencusIncome.test.txt', sep=\",\\s\",header=None, names=[\"age\", \"workclass\", \"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"50K\"], engine='python')\n",
    "\n",
    "#add & uncomment these two if you want to ignore the ? value\n",
    "#, na_values=[\"?\"]\n",
    "#cen.dropna(inplace=True)\n",
    "\n",
    "census_data = cen[[\"age\", \"workclass\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\"]]\n",
    "census_target = cen[\"50K\"]\n",
    "#print(census_target)\n",
    "\n",
    "#changing target into float 0 and 1\n",
    "new = []\n",
    "\n",
    "for index, item in enumerate(census_target):\n",
    "    if (item == \"<=50K.\"):\n",
    "        new.append(0.0)\n",
    "    else:\n",
    "        if(item == \">50K.\"):\n",
    "            new.append(1.0)\n",
    "        else:\n",
    "            new.append(2.0)\n",
    "\n",
    "new = np.array(new)            \n",
    "\n",
    "new_data = pd.get_dummies(census_data)\n",
    "\n",
    "print(new_data)\n",
    "\n",
    "#Fixing unbalanced column problem\n",
    "list_target = (list(new_data.columns.values))\n",
    "\n",
    "empty_list = (list(set(list_census) - set(list_target)))\n",
    "\n",
    "while (len(empty_list) > 0):\n",
    "    new_data[empty_list.pop()] = 0\n",
    "\n",
    "new_data = new_data.values\n",
    "\n",
    "clf = joblib.load('clf.pkl') # membaca model dari file eksternal\n",
    "print('Model Loaded!')\n",
    "\n",
    "\n",
    "\n",
    "#predicting learning data \n",
    "prediction = clf.predict(new_data)\n",
    "print('PREDICTION: ',prediction)\n",
    "print('TARGET TEST : ',new)\n",
    "\n",
    "#lihat akurasi\n",
    "print('\\nAccuracy:')\n",
    "acc = accuracy_score(new,prediction)\n",
    "print(acc*100,'%')\n",
    "\n",
    "graph = Source( tree.export_graphviz(clf, out_file=None))\n",
    "png_bytes = graph.pipe(format='png')\n",
    "with open('dtree_pipe.png','wb') as f:\n",
    "    f.write(png_bytes)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(png_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
